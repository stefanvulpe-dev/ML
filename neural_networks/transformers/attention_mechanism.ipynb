{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Attention Mechanism\n",
    "\n",
    "This notebook presents the self-attention mechanism, which is a key component of the Transformer model. The self-attention mechanism allows the model to focus on different parts of the input sequence when making predictions. This is particularly useful for tasks that involve long sequences, such as machine translation and text generation.\n",
    "The input sentence is first transformed into a sequence of vectors, which are then used to compute the attention scores. The attention scores are used to compute a weighted sum of the input vectors, which is then passed through a feedforward neural network to produce the final output.\n",
    "\n",
    "Input sentence -> Input vectors -> Attention scores -> Weighted sum -> Feedforward neural network -> Output\n",
    "\n",
    "The input vectors are typically obtained by embedding the input tokens into a high-dimensional vector space. The attention scores are computed using a similarity function, which measures how similar each input vector is to the current context vector. These vectors are:\n",
    "- Query vector: What I am looking for\n",
    "- Key vector: What I am looking at\n",
    "- Value vector: What I am paying attention to\n",
    "\n",
    "Input sentence example: \"The cat sat on the mat.\""
   ],
   "id": "7a0c4870d4f3b3b3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T09:39:02.843100Z",
     "start_time": "2024-10-10T09:39:02.839871Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from math import inf"
   ],
   "id": "c68c01d9501a4e18",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T09:25:10.807259Z",
     "start_time": "2024-10-10T09:25:10.803293Z"
    }
   },
   "cell_type": "code",
   "source": "sentence = [\"The\", \"cat\", \"sat\", \"on\", \"the\", \"mat.\"]",
   "id": "ff87aee2cc1c9283",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T09:47:39.081743Z",
     "start_time": "2024-10-10T09:47:39.076208Z"
    }
   },
   "cell_type": "code",
   "source": [
    "q = np.random.randn(6, 4)\n",
    "k = np.random.randn(6, 4)\n",
    "v = np.random.randn(6, 4)\n",
    "\n",
    "print(q)\n",
    "print(k)\n",
    "print(v)"
   ],
   "id": "4a7fd377d4e021a8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.17726915 -0.60715105  0.27040047  1.32262995]\n",
      " [-0.35466501 -1.00190095  0.49971724  0.52404003]\n",
      " [-0.96664612 -0.92880235  0.31031606  1.47667384]\n",
      " [ 2.58801299  0.91252951  0.47811754 -1.90542747]\n",
      " [ 0.39023975  1.89121848 -0.77398807  0.55986816]\n",
      " [-0.11781247  0.66704404  0.74030888  0.80908705]]\n",
      "[[ 1.31088812  0.03025595  0.02526448 -0.6110974 ]\n",
      " [ 0.03582415  0.53263921 -0.34596446  0.67464531]\n",
      " [-0.21136     1.38581759 -2.44668208 -0.46287517]\n",
      " [-0.4030099  -0.90153947 -0.72863338 -1.69069868]\n",
      " [-0.05841235  0.88533137  0.23723818  1.64457024]\n",
      " [ 0.90458896 -0.71120042 -0.77826392  1.28070143]]\n",
      "[[ 0.76514641 -1.69868336 -1.59656269 -0.76914076]\n",
      " [-0.81664305 -0.10608875 -1.38933315 -2.52314108]\n",
      " [ 0.20812633  0.43433177 -1.68935144 -0.07477778]\n",
      " [ 1.00473554  0.71972715 -0.40171648 -0.90225516]\n",
      " [-1.03943008 -2.32277988  1.68366562  0.53501308]\n",
      " [ 1.49572558  0.46566221 -0.26506452  1.31825037]]\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\\begin{align}\n",
    "self attention(Q, K, V) = softmax \\left( \\dfrac{Q \\cdot K^T}{\\sqrt{d_k}} + M \\right) \\cdot V\n",
    "\\end{align}"
   ],
   "id": "18d3f2a61f64c934"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Masking\n",
    "The masking matrix $M$ is used to prevent the model from attending to certain parts of the input sequence. For example, in machine translation tasks, the model should not be allowed to attend to the future tokens in the input sequence. This is achieved by setting the masking matrix to zero for the future tokens and one for the past tokens."
   ],
   "id": "95a4ef5897730177"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T09:47:43.099091Z",
     "start_time": "2024-10-10T09:47:43.092639Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_mask(size):\n",
    "    mask = np.tril(np.ones((size, size)))\n",
    "    mask[mask == 0] = -inf\n",
    "    mask[mask == 1] = 0\n",
    "    return mask\n",
    "\n",
    "mask = create_mask(len(sentence))\n",
    "mask"
   ],
   "id": "510ce5e81e498788",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0., -inf, -inf, -inf, -inf, -inf],\n",
       "       [  0.,   0., -inf, -inf, -inf, -inf],\n",
       "       [  0.,   0.,   0., -inf, -inf, -inf],\n",
       "       [  0.,   0.,   0.,   0., -inf, -inf],\n",
       "       [  0.,   0.,   0.,   0.,   0., -inf],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "328cc73471991141"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T09:38:02.968203Z",
     "start_time": "2024-10-10T09:38:02.964101Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def softmax(x):\n",
    "    exp_x = np.exp(x)\n",
    "    return exp_x / np.sum(exp_x, axis=1, keepdims=True)"
   ],
   "id": "b7a634ac0d90ce75",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T09:47:50.961359Z",
     "start_time": "2024-10-10T09:47:50.956362Z"
    }
   },
   "cell_type": "code",
   "source": [
    "w = softmax(np.dot(q, k.T) + mask)\n",
    "w"
   ],
   "id": "3008b0e378bf9650",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.39241945, 0.60758055, 0.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.06890137, 0.8818494 , 0.04924923, 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.95480366, 0.00402563, 0.01479945, 0.02637126, 0.        ,\n",
       "        0.        ],\n",
       "       [0.01492158, 0.06423303, 0.78734935, 0.00128508, 0.13221096,\n",
       "        0.        ],\n",
       "       [0.04566295, 0.15950434, 0.02440449, 0.00717102, 0.68879132,\n",
       "        0.07446588]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Here, \"sat\" focuses on \"cat\" and \"on\" focuses on \"the\".",
   "id": "56989bfc2c3bd6de"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T09:43:24.717367Z",
     "start_time": "2024-10-10T09:43:24.713608Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def attention(q, k, v, mask=None):\n",
    "    scaled = np.dot(q, k.T)\n",
    "    if mask is not None:\n",
    "        scaled = scaled + mask\n",
    "    weights = softmax(scaled)\n",
    "    output = np.dot(weights, v)\n",
    "    return output"
   ],
   "id": "7baca1c1022ac944",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T09:47:57.802214Z",
     "start_time": "2024-10-10T09:47:57.797450Z"
    }
   },
   "cell_type": "code",
   "source": [
    "self_attention = attention(q, k, v, mask)\n",
    "self_attention"
   ],
   "id": "db0631e73bdaa539",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.76514641, -1.69868336, -1.59656269, -0.76914076],\n",
       "       [-0.19591809, -0.73105386, -1.47065405, -1.83483723],\n",
       "       [-0.65718648, -0.18920541, -1.41838721, -2.28170805],\n",
       "       [ 0.75685338, -1.59692818, -1.56559208, -0.76943592],\n",
       "       [-0.01330302,  0.00363734, -1.22109125, -0.1628469 ],\n",
       "       [-0.68760497, -1.64396236,  0.80133911,  0.02080885]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Multi-head Attention\n",
    "The multi-head attention mechanism allows the model to attend to different parts of the input sequence in parallel. This is achieved by splitting the input vectors into multiple heads, which are then processed independently. The outputs of the different heads are concatenated and passed through a linear transformation to produce the final output. This allows the model to capture different aspects of the input sequence and learn more complex patterns.\n",
    "\n",
    "Input sentence -> Input vectors -> Split into multiple heads -> Process independently -> Concatenate outputs -> Linear transformation -> Output\n",
    "\n",
    "Parameters involved:\n",
    "- $d_{model}$: Dimension of the input vectors\n",
    "- $d_{k}$: Dimension of the key vectors\n",
    "- $d_{v}$: Dimension of the value vectors\n",
    "- $h$: Number of heads"
   ],
   "id": "c49a666106e7a623"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T10:14:53.117657Z",
     "start_time": "2024-10-10T10:14:48.832670Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ],
   "id": "8f49c2a1c620b142",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T10:16:59.155631Z",
     "start_time": "2024-10-10T10:16:59.151517Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sequence_length = 6 # Length of the input sequence\n",
    "batch_size = 1 # Number of sequences in a batch\n",
    "d_model = 512 # Dimension of the input vectors\n",
    "\n",
    "x = torch.randn(batch_size, sequence_length, d_model) # encoding of the input sequence\n",
    "x.size()"
   ],
   "id": "ae9c885b943204f3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6, 512])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T10:17:38.386409Z",
     "start_time": "2024-10-10T10:17:38.376335Z"
    }
   },
   "cell_type": "code",
   "source": [
    "qkv_layer = nn.Linear(d_model, 3 * d_model)\n",
    "qkv = qkv_layer(x)\n",
    "qkv.size()"
   ],
   "id": "e118c7fe2a6cd409",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6, 1536])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T10:19:00.370714Z",
     "start_time": "2024-10-10T10:19:00.365692Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_heads = 8 # Number of heads\n",
    "d_k = d_model // num_heads # Dimension of the key vectors\n",
    "d_v = d_model // num_heads # Dimension of the value vectors\n",
    "\n",
    "qkv = qkv.reshape(batch_size, sequence_length, num_heads, 3 * d_k)\n",
    "qkv.size()"
   ],
   "id": "5d959e4e5fa1fa54",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6, 8, 192])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T10:19:26.385079Z",
     "start_time": "2024-10-10T10:19:26.379411Z"
    }
   },
   "cell_type": "code",
   "source": [
    "qkv = qkv.permute(0, 2, 1, 3)\n",
    "qkv.size()"
   ],
   "id": "49ba531db16a0fc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 6, 192])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T10:21:48.726663Z",
     "start_time": "2024-10-10T10:21:48.720747Z"
    }
   },
   "cell_type": "code",
   "source": [
    "q, k, v = qkv.chunk(3, dim=-1)\n",
    "q.size(), k.size(), v.size() # [batch_size, num_heads, sequence_length, d_k]"
   ],
   "id": "4ebc8b2d76b4ea53",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 8, 6, 64]),\n",
       " torch.Size([1, 8, 6, 64]),\n",
       " torch.Size([1, 8, 6, 64]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T10:23:16.057817Z",
     "start_time": "2024-10-10T10:23:16.046682Z"
    }
   },
   "cell_type": "code",
   "source": [
    "scaled = torch.matmul(q, k.transpose(-2, -1)) / np.sqrt(d_k)\n",
    "scaled.size()"
   ],
   "id": "ee817486324a8487",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 6, 6])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T10:24:40.352463Z",
     "start_time": "2024-10-10T10:24:40.346158Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mask = torch.full(scaled.size(), float(-inf))\n",
    "mask = torch.triu(mask, diagonal=1)\n",
    "mask[0][1]"
   ],
   "id": "80db1068f9323143",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., -inf],\n",
       "        [0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T10:25:12.340348Z",
     "start_time": "2024-10-10T10:25:12.331776Z"
    }
   },
   "cell_type": "code",
   "source": [
    "scaled = scaled + mask\n",
    "\n",
    "attention_weights = F.softmax(scaled, dim=-1)\n",
    "attention_weights.size()"
   ],
   "id": "159cd3f2152c8fdc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 6, 6])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T10:25:39.447824Z",
     "start_time": "2024-10-10T10:25:39.443301Z"
    }
   },
   "cell_type": "code",
   "source": [
    "values = torch.matmul(attention_weights, v)\n",
    "values.size()"
   ],
   "id": "1856045df52e3572",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 6, 64])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T10:27:45.171567Z",
     "start_time": "2024-10-10T10:27:45.167426Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def scaled_dot_product(q, k, v, mask=None):\n",
    "    scaled = torch.matmul(q, k.transpose(-2, -1)) / np.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        scaled = scaled + mask\n",
    "    attention_weights = F.softmax(scaled, dim=-1)\n",
    "    values = torch.matmul(attention_weights, v)\n",
    "    return attention_weights, values"
   ],
   "id": "3457242d6c7563",
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T10:28:08.246165Z",
     "start_time": "2024-10-10T10:28:08.240265Z"
    }
   },
   "cell_type": "code",
   "source": [
    "attention_weights, values = scaled_dot_product(q, k, v, mask)\n",
    "attention_weights.size(), values.size()"
   ],
   "id": "1a6b41e0f224b28c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 64]))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T10:28:55.639232Z",
     "start_time": "2024-10-10T10:28:55.634580Z"
    }
   },
   "cell_type": "code",
   "source": [
    "values = values.reshape(batch_size, sequence_length, num_heads * d_v)\n",
    "values.size()"
   ],
   "id": "a60d1ed75c7d50fb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6, 512])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T10:29:54.282957Z",
     "start_time": "2024-10-10T10:29:54.276370Z"
    }
   },
   "cell_type": "code",
   "source": [
    "linear_layer = nn.Linear(num_heads * d_v, d_model)\n",
    "output = linear_layer(values)\n",
    "output.size()"
   ],
   "id": "6709f9de062f1fc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6, 512])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T10:35:48.115555Z",
     "start_time": "2024-10-10T10:35:48.108938Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_k = d_model // num_heads\n",
    "        self.d_v = d_model // num_heads\n",
    "        self.qkv_layer = nn.Linear(d_model, 3 * d_model)\n",
    "        self.linear_layer = nn.Linear(num_heads * self.d_v, d_model)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        print(f'x.size(): {x.size()}')\n",
    "        batch_size, sequence_length, _ = x.size()\n",
    "        qkv = self.qkv_layer(x)\n",
    "        print(f'qkv.size(): {qkv.size()}')\n",
    "        qkv = qkv.reshape(batch_size, sequence_length, self.num_heads, 3 * self.d_k)\n",
    "        print(f'qkv.size(): {qkv.size()}')\n",
    "        qkv = qkv.permute(0, 2, 1, 3)\n",
    "        print(f'qkv.size(): {qkv.size()}')\n",
    "        q, k, v = qkv.chunk(3, dim=-1)\n",
    "        print(f'q.size(): {q.size()}, k.size(): {k.size()}, v.size(): {v.size()}')\n",
    "        attention_weights, values = scaled_dot_product(q, k, v, mask)\n",
    "        print(f'attention_weights.size(): {attention_weights.size()}, values.size(): {values.size()}')\n",
    "        values = values.reshape(batch_size, sequence_length, self.num_heads * self.d_v)\n",
    "        output = self.linear_layer(values)\n",
    "        print(f'output.size(): {output.size()}')\n",
    "        return output"
   ],
   "id": "fef6d9a2ec2568d3",
   "outputs": [],
   "execution_count": 68
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T10:35:49.426626Z",
     "start_time": "2024-10-10T10:35:49.416565Z"
    }
   },
   "cell_type": "code",
   "source": [
    "multi_head_attention = MultiHeadAttention(d_model, num_heads)\n",
    "new_values = multi_head_attention(x, mask)"
   ],
   "id": "fe9fca6433f1d4d2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.size(): torch.Size([1, 6, 512])\n",
      "qkv.size(): torch.Size([1, 6, 1536])\n",
      "qkv.size(): torch.Size([1, 6, 8, 192])\n",
      "qkv.size(): torch.Size([1, 8, 6, 192])\n",
      "q.size(): torch.Size([1, 8, 6, 64]), k.size(): torch.Size([1, 8, 6, 64]), v.size(): torch.Size([1, 8, 6, 64])\n",
      "attention_weights.size(): torch.Size([1, 8, 6, 6]), values.size(): torch.Size([1, 8, 6, 64])\n",
      "output.size(): torch.Size([1, 6, 512])\n"
     ]
    }
   ],
   "execution_count": 69
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
